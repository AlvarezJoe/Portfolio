{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c660de29",
   "metadata": {},
   "source": [
    "# Model Monitoring with Evidently AI\n",
    "\n",
    "This notebook demonstrates comprehensive model monitoring capabilities using Evidently AI for automated drift detection and performance analysis. The implementation showcases production-ready monitoring workflows for machine learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from monitoring import generate_drift_report, load_model_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbba64a",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "Load baseline reference data and simulated drift scenarios for comprehensive monitoring analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baseline data\n",
    "baseline_data = pd.read_csv('../data/processed/housing_baseline.csv')\n",
    "print(f\"baseline data shape: {baseline_data.shape}\")\n",
    "\n",
    "# load drift scenarios\n",
    "drift_scenario_1 = pd.read_csv('../data/processed/housing_drift_scenario_1.csv')\n",
    "drift_scenario_2 = pd.read_csv('../data/processed/housing_drift_scenario_2.csv')\n",
    "\n",
    "print(f\"drift scenario 1 shape: {drift_scenario_1.shape}\")\n",
    "print(f\"drift scenario 2 shape: {drift_scenario_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748edbc",
   "metadata": {},
   "source": [
    "## Evidently AI Drift Report Generation\n",
    "\n",
    "Generate comprehensive drift detection reports using Evidently AI's automated monitoring capabilities. These reports provide detailed analysis of data distribution changes and feature drift patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate report for scenario 1 - feature drift\n",
    "report_1 = generate_drift_report(\n",
    "    reference_data=baseline_data,\n",
    "    current_data=drift_scenario_1,\n",
    "    report_name='drift_scenario_1'\n",
    ")\n",
    "\n",
    "print(\"drift report 1 generated successfully\")\n",
    "print(f\"report saved to: ../reports/drift_scenario_1_{datetime.now().strftime('%Y%m%d_%H%M')}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb302b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate report for scenario 2 - distribution change\n",
    "report_2 = generate_drift_report(\n",
    "    reference_data=baseline_data,\n",
    "    current_data=drift_scenario_2, \n",
    "    report_name='drift_scenario_2'\n",
    ")\n",
    "\n",
    "print(\"drift report 2 generated successfully\")\n",
    "print(f\"report saved to: ../reports/drift_scenario_2_{datetime.now().strftime('%Y%m%d_%H%M')}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70195da1",
   "metadata": {},
   "source": [
    "## Statistical Drift Analysis\n",
    "\n",
    "Perform detailed statistical analysis of drift detection results to identify specific features experiencing distribution changes and quantify the magnitude of detected drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check drift detection metrics\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.report import Report\n",
    "\n",
    "# create detailed drift analysis\n",
    "drift_report = Report(metrics=[\n",
    "    DataDriftPreset()\n",
    "])\n",
    "\n",
    "# run on scenario 1\n",
    "drift_report.run(reference_data=baseline_data, current_data=drift_scenario_1)\n",
    "drift_results = drift_report.as_dict()\n",
    "\n",
    "print(\"data drift analysis - scenario 1:\")\n",
    "print(f\"dataset drift detected: {drift_results['metrics'][0]['result']['dataset_drift']}\")\n",
    "print(f\"number of drifted features: {drift_results['metrics'][0]['result']['number_of_drifted_columns']}\")\n",
    "print(f\"share of drifted features: {drift_results['metrics'][0]['result']['share_of_drifted_columns']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze which specific features are drifting\n",
    "drift_by_feature = drift_results['metrics'][0]['result']['drift_by_columns']\n",
    "\n",
    "print(\"\\nfeature-level drift analysis:\")\n",
    "for feature, drift_info in drift_by_feature.items():\n",
    "    if drift_info['drift_detected']:\n",
    "        print(f\"{feature}: drift detected (p-value: {drift_info['stattest_threshold']:.4f})\")\n",
    "    else:\n",
    "        print(f\"{feature}: no drift detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92763ca9",
   "metadata": {},
   "source": [
    "## Model Performance Monitoring\n",
    "\n",
    "Evaluate model prediction performance on baseline versus drift scenarios to assess the impact of data drift on model accuracy and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model for prediction comparison\n",
    "model, feature_columns = load_model_and_data()\n",
    "\n",
    "# make predictions on baseline and drift data\n",
    "baseline_features = baseline_data[feature_columns]\n",
    "drift_features = drift_scenario_1[feature_columns]\n",
    "\n",
    "baseline_predictions = model.predict(baseline_features)\n",
    "drift_predictions = model.predict(drift_features)\n",
    "\n",
    "print(\"prediction statistics:\")\n",
    "print(f\"baseline predictions mean: {baseline_predictions.mean():.2f}\")\n",
    "print(f\"drift scenario predictions mean: {drift_predictions.mean():.2f}\")\n",
    "print(f\"prediction shift: {(drift_predictions.mean() - baseline_predictions.mean()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e1288",
   "metadata": {},
   "source": [
    "## Performance Degradation Analysis\n",
    "\n",
    "Quantify model performance degradation using standard regression metrics to establish monitoring thresholds and trigger automated alerts for significant performance decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# calculate model performance on baseline vs drift data\n",
    "baseline_mse = mean_squared_error(baseline_data['MedHouseVal'], baseline_predictions)\n",
    "baseline_mae = mean_absolute_error(baseline_data['MedHouseVal'], baseline_predictions)\n",
    "\n",
    "drift_mse = mean_squared_error(drift_scenario_1['MedHouseVal'], drift_predictions)\n",
    "drift_mae = mean_absolute_error(drift_scenario_1['MedHouseVal'], drift_predictions)\n",
    "\n",
    "print(\"model performance comparison:\")\n",
    "print(f\"baseline mse: {baseline_mse:.4f}\")\n",
    "print(f\"drift scenario mse: {drift_mse:.4f}\")\n",
    "print(f\"mse degradation: {((drift_mse - baseline_mse) / baseline_mse * 100):.2f}%\")\n",
    "print()\n",
    "print(f\"baseline mae: {baseline_mae:.4f}\")\n",
    "print(f\"drift scenario mae: {drift_mae:.4f}\")\n",
    "print(f\"mae degradation: {((drift_mae - baseline_mae) / baseline_mae * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc080c2",
   "metadata": {},
   "source": [
    "## Automated Monitoring Summary\n",
    "\n",
    "Generate comprehensive monitoring summaries for dashboard integration and automated alerting systems. This summary provides key metrics and alert triggers for production monitoring workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fd2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create monitoring summary\n",
    "monitoring_summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'data_drift_detected': drift_results['metrics'][0]['result']['dataset_drift'],\n",
    "    'drifted_features': drift_results['metrics'][0]['result']['number_of_drifted_columns'],\n",
    "    'baseline_mse': baseline_mse,\n",
    "    'current_mse': drift_mse,\n",
    "    'performance_degradation_pct': ((drift_mse - baseline_mse) / baseline_mse * 100),\n",
    "    'alert_triggered': drift_results['metrics'][0]['result']['dataset_drift'] or \n",
    "                     (((drift_mse - baseline_mse) / baseline_mse * 100) > 10)\n",
    "}\n",
    "\n",
    "print(\"monitoring summary:\")\n",
    "for key, value in monitoring_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# save summary for dashboard\n",
    "import json\n",
    "with open('../reports/monitoring_summary.json', 'w') as f:\n",
    "    json.dump(monitoring_summary, f, indent=2)\n",
    "\n",
    "print(\"\\nmonitoring summary saved for dashboard\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
