{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff81a92",
   "metadata": {},
   "source": [
    "# <center> Training Models with MLflow <center/>\n",
    "\n",
    "## <center> Building housing price models and tracking everything <center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c333ce5",
   "metadata": {},
   "source": [
    "# The Goal\n",
    "\n",
    "Now that we have our data prepped, it's time to train some models. We'll build housing price prediction models and use MLflow to track everything - experiments, parameters, metrics, and model artifacts.\n",
    "\n",
    "**We're building models that will serve as the foundation for our MLOps monitoring pipeline, where we can detect when performance starts to degrade over time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6999c2",
   "metadata": {},
   "source": [
    "# My Experience with MLOps\n",
    "Working with model deployment in production environments has taught me the importance of proper experiment tracking and model versioning. MLflow provides the infrastructure needed to maintain model lineage and compare experiments systematically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d813ae2",
   "metadata": {},
   "source": [
    "# Building Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab92ddf",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a535a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.tracking import MlflowClient\n",
    "import optuna\n",
    "from optuna.integration import MLflowCallback\n",
    "\n",
    "#our custom modules\n",
    "from data_loader import DataLoader\n",
    "from model_trainer import ModelTrainer\n",
    "\n",
    "#quality of life  \n",
    "np.random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries loaded successfully!\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73889e",
   "metadata": {},
   "source": [
    "## Getting Our Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11898e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize data loader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "#load our preprocessed training data\n",
    "print(\"Loading preprocessed training data...\")\n",
    "train_data = data_loader.load_processed_data(\"train_data.csv\")\n",
    "val_data = data_loader.load_processed_data(\"validation_data.csv\")\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "\n",
    "#this is how i like to display the shape of my df\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac032e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at our data\n",
    "print(\"First few rows:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTarget variable stats:\")\n",
    "print(train_data['MedHouseVal'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our model\n",
    "model = HousingPriceModel(model_type=\"xgboost\")\n",
    "\n",
    "# separate features from target\n",
    "print(\"Setting up features and target...\")\n",
    "\n",
    "X_train, y_train = model.prepare_features(train_data)\n",
    "X_val, y_val = model.prepare_features(val_data)\n",
    "\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Training target: {y_train.shape}\")\n",
    "print(f\"Validation features: {X_val.shape}\")\n",
    "print(f\"Validation target: {y_val.shape}\")\n",
    "\n",
    "print(f\"\\nFeatures we're using: {model.feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972114f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how our train/validation splits look\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if i < len(axes):\n",
    "        axes[i].hist(X_train[col], bins=30, alpha=0.7, color='skyblue', label='Train')\n",
    "        axes[i].hist(X_val[col], bins=30, alpha=0.7, color='orange', label='Validation')\n",
    "        axes[i].set_title(f'{col}')\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Feature Distributions: Train vs Validation', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ddc96",
   "metadata": {},
   "source": [
    "# MLflow Setup\n",
    "\n",
    "Time to set up experiment tracking. This will help us compare models and keep track of what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552677ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure MLflow\n",
    "mlflow.set_tracking_uri(\"../mlruns\")  # local tracking\n",
    "experiment_name = \"housing_price_prediction\"\n",
    "\n",
    "# create or get experiment\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    print(f\"Created new experiment: {experiment_name}\")\n",
    "except:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "    print(f\"Using existing experiment: {experiment_name}\")\n",
    "\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e889ba",
   "metadata": {},
   "source": [
    "# <center>XGBoost Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search params\n",
    "search_space_xgb = {\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 10),\n",
    "    'subsample': (0.6, 1.0),\n",
    "    'colsample_bytree': (0.6, 1.0),\n",
    "    'reg_alpha': (0, 10),\n",
    "    'reg_lambda': (0, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define objective function for optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, val_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "#create optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "#optimize hyperparameters\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ac99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best params for xgboost using optuna\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6eb06",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65085ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model with best params from optuna\n",
    "xgb_tuned = XGBRegressor(\n",
    "    colsample_bytree=study.best_params['colsample_bytree'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    reg_alpha=study.best_params['reg_alpha'],\n",
    "    reg_lambda=study.best_params['reg_lambda'],\n",
    "    subsample=study.best_params['subsample'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train tuned model\n",
    "xgb_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e39906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse for our tuned model\n",
    "mean_squared_error(y_val, xgb_tuned.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining feature importance descending for XGBoost\n",
    "feature_imp_xgb = pd.Series(xgb_tuned.feature_importances_, \n",
    "                           X_train.columns[xgb_tuned.feature_importances_!=0])\n",
    "feature_imp_xgb.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc sorting bar chart for feature importance\n",
    "sorted_idx = xgb_tuned.feature_importances_.argsort()\n",
    "plt.barh(\n",
    "    X_train.columns[sorted_idx], \n",
    "    xgb_tuned.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"XGBoostRegressor Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3017916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and validation predictions\n",
    "y_train_pred = xgb_tuned.predict(X_train)\n",
    "y_val_pred = xgb_tuned.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating training and validation mse\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(\"XGBoost Train MSE:\", mse_train)\n",
    "print(\"XGBoost Validation MSE:\", mse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the trained model\n",
    "import joblib\n",
    "joblib.dump(xgb_tuned, '../models/xgboost_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating baseline data for monitoring\n",
    "baseline_data = pd.concat([X_train, y_train], axis=1)\n",
    "baseline_data.to_csv('../data/processed/baseline_data.csv', index=False)\n",
    "print(\"Baseline data saved for monitoring purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d791c",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We successfully trained an XGBoost regression model with Optuna hyperparameter optimization. The model achieved decent performance on the housing price prediction task, and we've set up the foundation for continuous monitoring with MLflow experiment tracking. The baseline data has been prepared for drift detection in our MLOps pipeline."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
